{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum numbers with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: intro about task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: intro about Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- import tensorflow - should work!!! + google colab cu acces doar de rulare? sau doar de citire/copiere\n",
    "- Bibliografie\n",
    "- link catre prezentare??????\n",
    "- articol? nu cred, pt ca e o idee \"imprumutata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/mdiannna/.local/lib/python3.6/site-packages (1.5.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow) (3.9.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-tensorboard<1.6.0,>=1.5.0 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow) (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow) (1.15.4)\n",
      "Requirement already satisfied: setuptools in /home/mdiannna/.local/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow) (40.6.3)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow) (0.9999999)\n",
      "Requirement already satisfied: bleach==1.5.0 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/mdiannna/.local/lib/python3.6/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow) (0.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow             1.5.0              \n",
      "tensorflow-estimator   1.14.0             \n",
      "tensorflow-tensorboard 1.5.1              \n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting h5py==2.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.7 in /home/mdiannna/.local/lib/python3.6/site-packages (from h5py==2.8.0) (1.15.4)\n",
      "Requirement already satisfied: six in /home/mdiannna/.local/lib/python3.6/site-packages (from h5py==2.8.0) (1.12.0)\n",
      "Installing collected packages: h5py\n",
      "  Found existing installation: h5py 2.9.0\n",
      "    Uninstalling h5py-2.9.0:\n",
      "      Successfully uninstalled h5py-2.9.0\n",
      "Successfully installed h5py-2.8.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " !pip list | grep tensorflow \n",
    "!    pip install h5py==2.8.0 --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 + 396 = 465\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def generate_random_number(max_digits=3):\n",
    "    return randint(0, 10**max_digits)\n",
    "\n",
    "x1 = generate_random_number(3)\n",
    "x2 = generate_random_number()\n",
    "print(x1, '+',x2, '=', x1+x2)\n",
    "\n",
    "# Note: Daca ambele numere au maxim 3 cifre, suma va avea maxim 4 cifre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, individual digits will be transformed to characters for each number.\n",
    "\n",
    "*eg. a=123, b=4 will be transformed in '['1', '2', '3'] and ['4']*\n",
    "\n",
    "- After that, will use padding to obtain arrays of equal size (3 characters); The value of 10 is used for padding, because it will be the 10th character in the alphabet.\n",
    "\n",
    "*a = ['1','2','3'], b=['10','10','4']*\n",
    "\n",
    "- After that, digit characters for both numbers will be concatenated.\n",
    "\n",
    "*['1','2','3',.'10','10','4']*\n",
    "\n",
    "- And last, will use one hot encoding for encoding.\n",
    "\n",
    "*[0 1 0 0 0 0 0 0 0 0 0]*\n",
    "\n",
    "*[0 0 1 0 0 0 0 0 0 0 0]*\n",
    "\n",
    "*[0 0 0 1 0 0 0 0 0 0 0]*\n",
    "\n",
    "*[0 0 0 0 0 0 0 0 0 0 1]*\n",
    "\n",
    "*[0 0 0 0 0 0 0 0 0 0 1]*\n",
    "\n",
    "*[0 0 0 0 1 0 0 0 0 0 0]*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def separate_digits(number):\n",
    "    return [int(i) for i in str(number)]\n",
    "\n",
    "\n",
    "def encode_numbers(number1, number2, max_lenght = 3, is_train = True):\n",
    "    digits_str = []\n",
    "    a = separate_digits(number1)\n",
    "    b = separate_digits(number2)\n",
    "        \n",
    "#     X = np.zeros(((max_lenght)*2, 11))\n",
    "#     Y = np.zeros((max_lenght, 11))\n",
    "  \n",
    "#     s = number1 + number2\n",
    "#     s = separate_digits(s)\n",
    "    \n",
    "#     if is_train:\n",
    "#         x , y = np.concatenate([a,b]), s\n",
    "#     else:\n",
    "#         a,b = pad_sequences([a,b],maxlen = max_lenght, value=10)\n",
    "#         x = np.concatenate([a,b])\n",
    "\n",
    "#     for j, char in enumerate(x):\n",
    "#          X[j, char] = 1\n",
    "     \n",
    "#     if(is_train):\n",
    "#         for j, char in enumerate(s):\n",
    "#             Y[j, char] = 1\n",
    "#     return X, Y\n",
    "          \n",
    "    \n",
    "encode_numbers(124, 342)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numbers(numbers_dataset, is_train=False, max_lenght = 3):\n",
    "  n = len(numbers_dataset)\n",
    "#   print(numbers_dataset[0][0])\n",
    "  X = np.zeros((n, (max_lenght)*2, 11))\n",
    "  Y = np.zeros((n, max_lenght, 11))\n",
    "  \n",
    "  for i in range(n):\n",
    "    a = numbers_dataset[i][0]\n",
    "    b = numbers_dataset[i][1]\n",
    "    \n",
    "    if(is_train):\n",
    "      s = a + b\n",
    "      s = [int(i) for i in str(s)]\n",
    "\n",
    "    a = [int(i) for i in str(a)]\n",
    "    b = [int(i) for i in str(b)]\n",
    "  \n",
    "    print(a,b)\n",
    "    \n",
    "    if is_train:\n",
    "      a,b,s = pad_sequences([a,b,s],maxlen = max_lenght, value=10)\n",
    "      x , y = np.concatenate([a,b]), s\n",
    "    else:\n",
    "      a,b = pad_sequences([a,b],maxlen = max_lenght, value=10)\n",
    "      x = np.concatenate([a,b])\n",
    "\n",
    "    for j, char in enumerate(x):\n",
    "         X[i, j, char] = 1\n",
    "     \n",
    "    if(is_train):\n",
    "      for j, char in enumerate(s):\n",
    "         Y[i, j, char] = 1\n",
    "          \n",
    "  if(is_train):\n",
    "      return X, Y\n",
    "  return X\n",
    "\n",
    "X , Y = encode_numbers(numbers, True)\n",
    "\n",
    "# print(numbers[0:10])\n",
    "# print(X[0:10])\n",
    "# print(Y[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - Configure network and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' ']\n",
    "chars_len = len(alphabet)\n",
    "\n",
    "input_len = 6\n",
    "output_len = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(input_len, chars_len)))\n",
    "model.add(RepeatVector(output_len))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(chars_len, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, Y, epochs=20)\n",
    "model.fit(X, Y, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network outputs the results being one hot encoded, this is why a function for decoding is needed. This function takes the maximum argument for each row and determines the individual digit, then we use the integer_combine function to combine digits and obtain the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-36d794c87b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "def decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "def integer_combine(n_array):\n",
    "  result = 0\n",
    "  for num in n_array:\n",
    "    if(num!=10):\n",
    "      result = result * 10 + round(num)\n",
    "  return result\n",
    "\n",
    "y = Y.astype(int)\n",
    "\n",
    "print(y.shape)\n",
    "result1 = [integer_combine(decode(x)) for x in y]\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on new data and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NR_SAMPLES_TEST = 3000\n",
    "NR_SAMPLES_TEST = 100\n",
    "\n",
    "# TODO: generate_numbers\n",
    "generator = test_generator(batch_size=NR_SAMPLES_TEST)\n",
    "\n",
    "x_test, numbers_test, numbers_sum_test = next(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = encode_numbers(numbers_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(X_test)\n",
    "\n",
    "# predicted = [invert(x, alphabet) for x in result]\n",
    "predicted = [integer_combine(decode(x)) for x in result]\n",
    "expected = [integer_combine(decode(x)) for x in Y_test]\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"Loss on test set: %f\" % loss)\n",
    "print(\"Accuracy on test set: %f\" % acc)\n",
    "# print(\"Mean squared error:\")\n",
    "mse = mean_squared_error(expected, predicted)\n",
    "print('Mean squared error: %f' % mse)\n",
    "\n",
    "# rmse = sqrt(mean_squared_error(expected, predicted))\n",
    "# print('RMSE: %f' % rmse)\n",
    "\n",
    "print(\"--First 20 examples result:--\")\n",
    "for i in range(20):\n",
    "\tprint('Expected=%s, Predicted=%s' % (expected[i], predicted[i]))\n",
    "\tprint('Difference=%s' % (abs(expected[i] - predicted[i])))\n",
    "  \n",
    "plt.plot(expected, predicted, 'oc')\n",
    "plt.xlabel(\"Expected\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-837d84333dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SUM_NUMBERS1.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# for loading model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = load_model('sum_digits_RNN.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME = \"SUM_NUMBERS1.h5\"\n",
    "model.save(MODEL_NAME)\n",
    "# for loading model:\n",
    "# model = load_model('sum_digits_RNN.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a model for adding 2 numbers using a neural network. The strategy used for this task was to build an encoder-decoder model architecture (also named sequence to sequence) and predict the sum of the integers based on encoded sequences of initial numbers. The neural network consisted of 2 LSTM layers (the first with 100 cells and the second with 50) and a Dense layer. The accuracy obtained on the training set was 99.28% and on the test set was 99.04%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3",
   "language": "python",
   "name": "p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
